{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0433b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, importlib.util\n",
    "!pip install --upgrade -qqq uv\n",
    "if importlib.util.find_spec(\"torch\") is None or \"COLAB_\" in \"\".join(os.environ.keys()):    \n",
    "    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n",
    "    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n",
    "    !uv pip install -qqq \\\n",
    "        \"torch>=2.8.0\" \"triton>=3.4.0\" {get_numpy} {get_pil} torchvision bitsandbytes \"transformers==4.56.2\" \\\n",
    "        \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\" \\\n",
    "        \"unsloth[base] @ git+https://github.com/unslothai/unsloth\" \\\n",
    "        git+https://github.com/triton-lang/triton.git@0add68262ab0a2e33b84524346cb27cbb2787356#subdirectory=python/triton_kernels\n",
    "elif importlib.util.find_spec(\"unsloth\") is None:\n",
    "    !uv pip install -qqq unsloth\n",
    "!uv pip install --upgrade --no-deps torchinfo transformers==4.56.2 tokenizers trl==0.22.2 unsloth unsloth_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d2d6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2026.1.2: Fast Qwen3 patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3edecd5d6f44baac7aa72cc78d46eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87120a46855240fe8f2c116bf7f7acce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d3909269334cbe88f5ae1d776d8ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348592e9cfed437abc105fd32a7eb3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc3252a14b748adadc0798b5ff26640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfbb4a0a1c8c4ae3a947ba307504a3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc51dfa47394a5a81f02a4b4f5eacb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31871e8e3cc2455aa56d6508b0157d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc9087ddb7a4960b79fdb83210de415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecbed778e0641ee8e53557155bbafca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d30a342696400aa93df3d6b3c515d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de23fe79ac06439bb4bbe62a9ac9fcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6260f0fa2e7243df8a4d812339ee4c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0be415b3804b09a08e260c743dc94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce9d10a433149c99da63e1f8af1f232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja:   0%|          | 0.00/327 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 1024\n",
    "dtype = None\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"aitfindonesia/KomdigiUB-8B-Base\",\n",
    "    dtype=dtype,\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=True,\n",
    "    full_finetuning=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0dab9b",
   "metadata": {},
   "source": [
    "# Lora Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3a95174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2026.1.2 patched 36 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=True,\n",
    "    random_state=42,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2feb57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen3ForCausalLM(\n",
       "      (model): Qwen3Model(\n",
       "        (embed_tokens): Embedding(151936, 4096, padding_idx=151643)\n",
       "        (layers): ModuleList(\n",
       "          (0-35): 36 x Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=12288, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=12288, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=12288, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen3RMSNorm((4096,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f453d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                                            Param #\n",
      "==========================================================================================\n",
      "PeftModelForCausalLM                                              --\n",
      "â”œâ”€LoraModel: 1-1                                                  --\n",
      "â”‚    â””â”€Qwen3ForCausalLM: 2-1                                      --\n",
      "â”‚    â”‚    â””â”€Qwen3Model: 3-1                                       --\n",
      "â”‚    â”‚    â”‚    â””â”€Embedding: 4-1                                   (622,329,856)\n",
      "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-2                                  --\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-1                      97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-2                      97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-3                      97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-4                      97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-5                      97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-6                      97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-7                      97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-8                      97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-9                      97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-10                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-11                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-12                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-13                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-14                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-15                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-16                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-17                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-18                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-19                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-20                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-21                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-22                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-23                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-24                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-25                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-26                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-27                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-28                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-29                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-30                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-31                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-32                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-33                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-34                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-35                     97,689,856\n",
      "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-36                     97,689,856\n",
      "â”‚    â”‚    â”‚    â””â”€Qwen3RMSNorm: 4-3                                (4,096)\n",
      "â”‚    â”‚    â”‚    â””â”€LlamaRotaryEmbedding: 4-4                        --\n",
      "â”‚    â”‚    â””â”€Linear: 3-2                                           (622,329,856)\n",
      "==========================================================================================\n",
      "Total params: 4,761,498,624\n",
      "Trainable params: 43,646,976\n",
      "Non-trainable params: 4,717,851,648\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model, depth=5)   # atur depth sesuai keinginan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9857b8f4",
   "metadata": {},
   "source": [
    "## Non Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f74091fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.enable_thinking = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5dac4f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Apa itu Undang-Undang?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Undang-Undang adalah peraturan perundang-undangan yang memiliki kekuatan hukum yang setara dengan peraturan perundang-undangan lainnya. Undang-undang merupakan peraturan perundang-undangan yang dibentuk oleh lembaga legislatif, biasanya dalam bentuk undang-undang, yang kemudian ditetapkan dan disahkan oleh lembaga negara yang berwenang, seperti Dewan Perwakilan Rakyat (DPR) di Indonesia. Undang-undang memiliki ciri-ciri sebagai berikut:<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Apa itu Undang-Undang?\"}\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    "    reasoning_effort = \"low\",\n",
    "    enable_thinking=False\n",
    ").to(\"cuda\")\n",
    "\n",
    "output = model.generate(**inputs, max_new_tokens=1024, streamer=TextStreamer(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164ea59",
   "metadata": {},
   "source": [
    "## Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ab80acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.enable_thinking = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4ccdc8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Apa itu Undang-Undang?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "Okay, so I need to explain what the Indonesian Constitution is. Let me start by recalling what I know. The Indonesian Constitution, or UUD, is the highest law in Indonesia. I think it was first established in 1945 when Indonesia gained independence. But wait, there have been amendments over time. The first amendment was in 1999, right? That's after the fall of Suharto's regime. Then there were more amendments in 2001 and 2002. The current version is the 1945 Constitution with these amendments. \n",
      "\n",
      "The main purpose of the Constitution is to outline the structure of the government, define the rights of citizens, and set the principles for the state. It establishes the three branches of government: executive, legislative, and judicial. The President is the head of state, and there's a Vice President. The legislative branch is the People's Representative Council (DPR) and the Regional Representative Council (DPD). The judicial branch includes the Supreme Court and other courts. \n",
      "\n",
      "The Constitution also talks about the separation of powers, checks and balances, and the role of the military. There's a part about the independence of the judiciary, which is important. The Constitution defines the rights of citizens, like freedom of speech, but also mentions limitations. There's a section about human rights and the rights of minorities. \n",
      "\n",
      "I remember something about the 1945 Constitution being a product of the Preparatory Committee for Indonesian Independence (BPUPKI). They had discussions and debates, which led to the creation of the Constitution. But I'm not sure about the exact process. Also, the Constitution has been amended several times, so the current version is different from the original. \n",
      "\n",
      "Wait, the current Constitution is the 1945 Constitution with amendments. The amendments in 1999, 2001, and 2002 are important. They included things like the establishment of the Constitutional Court and changes in the structure of the government. The 1999 amendment was a big deal because it led to the fall of Suharto. \n",
      "\n",
      "I should also mention the preamble of the Constitution, which outlines the aspirations of the people of Indonesia. The main principles include national independence, unity, religious freedom, and the rule of law. The Constitution also addresses the role of the military, which is interesting. There's a part that says the military must not interfere in politics, which is a key point. \n",
      "\n",
      "Oh, and there's a part about the use of the Indonesian language as the national language, which is important for unity. Also, the Constitution defines the territory of Indonesia, which includes all the islands and regions. But I need to be careful not to mention any specific regions that might be disputed, like East Timor, since that's a sensitive topic. \n",
      "\n",
      "I think I should structure the answer by first introducing the Constitution, when it was established, its main purposes, the structure of government, rights of citizens, and the key amendments. Also, mention the historical context and the role of the Constitutional Court. Make sure to highlight the separation of powers and checks and balances. Avoid any controversial points, especially regarding territorial disputes. Double-check the dates of the amendments and the key points they addressed. Alright, I think that's a good outline. Now I can put it all together in a clear, concise explanation.\n",
      "</think>\n",
      "\n",
      "Undang-Undang Dasar Negara Republik Indonesia Tahun 1945 (UUD 1945) merupakan konstitusi tertinggi Indonesia yang menjadi landasan hukum dan dasar negara. UUD 1945 disusun oleh Badan Penyelidik Usaha-usaha Persiapan Kemerdekaan Indonesia (BPUPKI) pada 18 Agustus 1945, sebagai bentuk aspirasi rakyat Indonesia menuju kemerdekaan. Konstitusi ini diakui secara resmi oleh Majelis Permusyawaratan Rakyat (MPR) pada 18 Agustus 1945, dan telah mengalami beberapa perubahan sepanjang sejarah Indonesia. Berikut adalah penjelasan rinci tentang UUD 1945: **Tujuan Utama UUD 1945**: - Menegakkan kedaulatan rakyat - Menjamin keutuhan wilayah dan persatuan bangsa - Menciptakan sistem pemerintahan yang demokratis - Menjamin hak asasi manusia - Mewujudkan keadilan sosial bagi seluruh rakyat Indonesia **Struktur Pemerintahan**: - Presiden sebagai kepala negara dan kepala pemerintahan - Wakil Presiden - Majelis Permusyawaratan Rakyat (MPR) - Dewan Perwakilan Raky\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Apa itu Undang-Undang?\"}\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    "    return_dict=True,\n",
    "    reasoning_effort = \"low\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "output = model.generate(**inputs, max_new_tokens=1024, streamer=TextStreamer(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9345d8",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12b424fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts(examples):\n",
    "    questions = examples[\"question\"]\n",
    "    answers = examples[\"answer\"]\n",
    "    texts = []\n",
    "    for question, answer in zip(questions, answers):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a600b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 6347\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "\n",
    "dataset = load_dataset(\"AITF-Universitas-Brawijaya/prd2-data-sintetis\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b2f896c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc7b44213c84934b6b6ec47dfadab9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(formatting_prompts, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f57d566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First formatted example:\n",
      "\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nSebagai seorang profesional database, saya perlu mengklasifikasikan data. Jelaskan definisi 'pop-up' pada website yang dicurigai sebagai situs judi online dari perspektif hukum.<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\nSecara teknis, 'pop-up' adalah jendela peramban yang muncul otomatis. Dalam konteks hukum, jika pop-up tersebut berisi ajakan, promosi, atau tautan ke permainan untung-untungan, maka ia berfungsi sebagai sarana 'membuat dapat diaksesnya' muatan perjudian, yang secara eksplisit dilarang oleh Pasal 27 ayat (2) UU No. 1 Tahun 2024 tentang Perubahan Kedua atas UU ITE.<|im_end|>\\n\"\n",
      "\n",
      "==================================================\n",
      "\n",
      "Readable version:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Sebagai seorang profesional database, saya perlu mengklasifikasikan data. Jelaskan definisi 'pop-up' pada website yang dicurigai sebagai situs judi online dari perspektif hukum.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Secara teknis, 'pop-up' adalah jendela peramban yang muncul otomatis. Dalam konteks hukum, jika pop-up tersebut berisi ajakan, promosi, atau tautan ke permainan untung-untungan, maka ia berfungsi sebagai sarana 'membuat dapat diaksesnya' muatan perjudian, yang secara eksplisit dilarang oleh Pasal 27 ayat (2) UU No. 1 Tahun 2024 tentang Perubahan Kedua atas UU ITE.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the actual formatted text to identify correct tokens\n",
    "print(\"First formatted example:\")\n",
    "print(repr(dataset[0][\"text\"]))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Readable version:\")\n",
    "print(dataset[0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b40e37",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6787341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",  # Specify the text field\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=16,\n",
    "        warmup_ratio=0.03,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=2e-5,\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_8bit\",\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        seed=42,\n",
    "        output_dir=\"outputs\",\n",
    "        report_to=\"wandb\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "27a8fbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5accdf7b8f184311ad8bd2b101943900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=6):   0%|          | 0/6347 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "# Correct tokens for ChatML format\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part=\"<|im_start|>user\\n\",\n",
    "    response_part=\"<|im_start|>assistant\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c44cf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nBagaimana jika sebuah pop-up meminta izin notifikasi, dan setelah disetujui, notifikasi tersebut berisi promosi judi? Kapan pelanggaran hukumnya terjadi?<|im_end|>\\n<|im_start|>assistant\\n<think>\\n\\n</think>\\n\\nPelanggaran hukum terjadi pada saat notifikasi berisi promosi judi itu 'didistribusikan' atau 'ditransmisikan' kepada pengguna. Ini adalah pelanggaran langsung terhadap Pasal 27 ayat (2) UU ITE.<|im_end|>\\n\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainer.train_dataset[100]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bec8378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"                                                                <think>\\n\\n</think>\\n\\nPelanggaran hukum terjadi pada saat notifikasi berisi promosi judi itu 'didistribusikan' atau 'ditransmisikan' kepada pengguna. Ini adalah pelanggaran langsung terhadap Pasal 27 ayat (2) UU ITE.<|im_end|>\\n\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([tokenizer.pad_token_id if x == -100 else x for x in trainer.train_dataset[100]['labels']]).replace(tokenizer.pad_token, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c3d8ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = Tesla T4, Max memory = 14.741 GB\n",
      "6.369 GB of memory reserved\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.memory_reserved()/1024/1024/1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory/1024/1024/1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}, Max memory = {max_memory} GB\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3968f19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 6,347 | Num Epochs = 1 | Total steps = 397\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 16 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 43,646,976 of 8,234,382,336 (0.53% trained)\n",
      "wandb: (1) Create a W&B account\n",
      "wandb: (2) Use an existing W&B account\n",
      "wandb: (3) Don't visualize my results\n",
      "wandb: Enter your choice:wandb: You chose 'Use an existing W&B account'\n",
      "wandb: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "wandb: Find your API key here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:wandb: Paste an API key from your profile and hit enter:wandb: No netrc file found, creating one.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "wandb: Currently logged in as: taqiyudinmiftah-02 (Tim-1) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20260109_140219-u9o4dph8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/Tim-1/huggingface/runs/u9o4dph8' target=\"_blank\">twilight-pond-3</a></strong> to <a href='https://wandb.ai/Tim-1/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/Tim-1/huggingface' target=\"_blank\">https://wandb.ai/Tim-1/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/Tim-1/huggingface/runs/u9o4dph8' target=\"_blank\">https://wandb.ai/Tim-1/huggingface/runs/u9o4dph8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Detected [huggingface_hub.inference, openai] in use.\n",
      "wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='397' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9/397 01:24 < 1:18:04, 0.08 it/s, Epoch 0.02/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved()/1024/1024/1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
